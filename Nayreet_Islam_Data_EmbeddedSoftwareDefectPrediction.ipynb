{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On the Prediction of Software Defects for Embedded Real-time Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import arff\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15123, 22)\n",
      "[[1.1 1.4 1.4 ..., 1.2 1.2 1.4]\n",
      " [1.0 1.0 1.0 ..., 1.0 1.0 1.0]\n",
      " [24.0 5.0 1.0 ..., 44.0 19.0 9.0]\n",
      " ..., \n",
      " [5.0 3.0 3.0 ..., 11.0 6.0 5.0]\n",
      " [18.0 8.0 5.0 ..., 61.0 50.0 15.0]\n",
      " [26.0 18.0 13.0 ..., 119.0 109.0 35.0]]\n"
     ]
    }
   ],
   "source": [
    "data_cm1 = arff.load(open('cm1.arff'))\n",
    "data_jm1 = arff.load(open('jm1.arff'))\n",
    "data_kc1 = arff.load(open('kc1.arff'))\n",
    "data_kc2 = arff.load(open('kc2.arff'))\n",
    "data_pc1 = arff.load(open('pc1.arff'))\n",
    "\n",
    "data1 = data_cm1['data']\n",
    "data2 = data_jm1['data']\n",
    "data3 = data_kc1['data']\n",
    "data4 = data_kc2['data']\n",
    "data5 = data_pc1['data']\n",
    "\n",
    "data11 = np.array(data1)\n",
    "\n",
    "data1.extend(data2)\n",
    "data1.extend(data3)  \n",
    "data1.extend(data4)  \n",
    "data1.extend(data5)  \n",
    "\n",
    "\n",
    "datacm1 = data11[:,0:21]\n",
    "labelscm1 = data11[:,21]\n",
    "\n",
    "\n",
    "\n",
    "data2 = np.array(data2)\n",
    "datajm1 = data2[:,0:21]\n",
    "labelsjm1 = data2[:,21]\n",
    "\n",
    "\n",
    "data3 = np.array(data3)\n",
    "datakc1 = data3[:,0:21]\n",
    "labelskc1 = data3[:,21]\n",
    "\n",
    "\n",
    "\n",
    "data4 = np.array(data4)\n",
    "datakc2 = data4[:,0:21]\n",
    "labelskc2 = data4[:,21]\n",
    "\n",
    "\n",
    "data5 = np.array(data5)\n",
    "datapc1 = data5[:,0:21]\n",
    "labelspc1 = data5[:,21]\n",
    "\n",
    "    \n",
    "data1 = np.array(data1)\n",
    "print(data1.shape)\n",
    "\n",
    "data = data1[:,0:21]\n",
    "labels = data1[:,21]\n",
    "\n",
    "\n",
    "#print(data.shape)\n",
    "#print(labels.shape)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting the label data to zero and one (from true/false or yes/no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_label(labels1):\n",
    "    labels = []\n",
    "    for i in range(len(labels1)):\n",
    "        if labels1[i] == 'false' or labels1[i] == 'no':\n",
    "            labels.append(0)\n",
    "        if labels1[i] == 'true' or labels1[i] == 'yes':\n",
    "            labels.append(1)\n",
    "            \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling convert_label() and Storing the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 ..., 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "labelsbefore = np.array(convert_label(labels))\n",
    "labelsbeforecm1 = np.array(convert_label(labelscm1))\n",
    "labelsbeforejm1 = np.array(convert_label(labelsjm1))\n",
    "labelsbeforekc1 = np.array(convert_label(labelskc1))\n",
    "labelsbeforekc2 = np.array(convert_label(labelskc2))\n",
    "labelsbeforepc1 = np.array(convert_label(labelspc1))\n",
    "\n",
    "print(labelsbefore)\n",
    "\n",
    "# for i in range(len(labelsbefore)):\n",
    "#     if labelsbefore[i] == 0 or labelsbefore[i] == 1:\n",
    "#         print(labelsbefore[i],labels[i])\n",
    "#     else:  \n",
    "#         print(\"******\")\n",
    "#         print(data[i])\n",
    "#         print(i)\n",
    "#         print(\"******\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying Missing Values and Replacing it with a zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replacing_missing_values(dataNew, labelsNew):\n",
    "    for i in range(len(dataNew)):\n",
    "        for j in range(dataNew.shape[1]):\n",
    "            if dataNew[i,j]== None:\n",
    "                dataNew[i][j] = 0\n",
    "                print('***')\n",
    "    for i in range(len(labelsNew)):\n",
    "        if labelsNew[i]== None:\n",
    "            labelsNew[i] = 0\n",
    "            print('************')\n",
    "    return dataNew, labelsNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n",
      "***\n"
     ]
    }
   ],
   "source": [
    "data,labelsbefore = replacing_missing_values(data, labelsbefore)\n",
    "datacm1,labelsbeforecm1 = replacing_missing_values(datacm1, labelsbeforecm1)\n",
    "datajm1,labelsbeforejm1 = replacing_missing_values(datajm1, labelsbeforejm1)\n",
    "datakc1,labelsbeforekc1 = replacing_missing_values(datakc1, labelsbeforekc1)\n",
    "datakc2,labelsbeforekc2 = replacing_missing_values(datakc2, labelsbeforekc2)\n",
    "datapc1,labelsbeforepc1 = replacing_missing_values(datapc1, labelsbeforepc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle_in_unison(a, b):\n",
    "\n",
    "    assert len(a) == len(b)\n",
    "    shuffled_a = np.empty(a.shape, dtype=a.dtype)\n",
    "    shuffled_b = np.empty(b.shape, dtype=b.dtype)\n",
    "    permutation = np.random.permutation(len(a))\n",
    "    \n",
    "    for old_index, new_index in enumerate(permutation):\n",
    "        shuffled_a[new_index] = a[old_index]\n",
    "        shuffled_b[new_index] = b[old_index]\n",
    "        \n",
    "    return shuffled_a, shuffled_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting the data into test and training sets randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##  Training and Testing set\n",
    "split_ratio = 0.2\n",
    "# Shuffle before splitting\n",
    "x, y = shuffle_in_unison(data, labelsbefore) \n",
    "xcm1, ycm1 = shuffle_in_unison(datacm1,labelsbeforecm1)\n",
    "xjm1, yjm1 = shuffle_in_unison(datajm1,labelsbeforejm1)\n",
    "xkc1, ykc1 = shuffle_in_unison(datakc1,labelsbeforekc1)\n",
    "xkc2, ykc2 = shuffle_in_unison(datakc2,labelsbeforekc2)\n",
    "xpc1, ypc1 = shuffle_in_unison(datapc1,labelsbeforepc1)\n",
    "\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(x, y, test_size=split_ratio)\n",
    "x_train1cm1, x_test1cm1, y_train1cm1, y_test1cm1 = train_test_split(xcm1, ycm1, test_size=split_ratio)\n",
    "x_train1jm1, x_test1jm1, y_train1jm1, y_test1jm1 = train_test_split(xjm1, yjm1, test_size=split_ratio)\n",
    "x_train1kc1, x_test1kc1, y_train1kc1, y_test1kc1 = train_test_split(xkc1, ykc1, test_size=split_ratio)\n",
    "x_train1kc2, x_test1kc2, y_train1kc2, y_test1kc2 = train_test_split(xkc2, ykc2, test_size=split_ratio)\n",
    "x_train1pc1, x_test1pc1, y_train1pc1, y_test1pc1 = train_test_split(xpc1, ypc1, test_size=split_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One _hot for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3025, 2)\n"
     ]
    }
   ],
   "source": [
    "y_train1_before= y_train1\n",
    "y_train_one_hot = np.eye(2)[y_train1_before]\n",
    "\n",
    "y_test1_before= y_test1\n",
    "y_test_one_hot  = np.eye(2)[y_test1_before]\n",
    "\n",
    "\n",
    "y_train1_beforecm1= y_train1cm1\n",
    "y_train_one_hotcm1 = np.eye(2)[y_train1_beforecm1]\n",
    "\n",
    "y_test1_beforecm1= y_test1cm1\n",
    "y_test_one_hotcm1  = np.eye(2)[y_test1_beforecm1]\n",
    "\n",
    "y_train1_beforejm1= y_train1jm1\n",
    "y_train_one_hotjm1 = np.eye(2)[y_train1_beforejm1]\n",
    "\n",
    "y_test1_beforejm1= y_test1jm1\n",
    "y_test_one_hotjm1  = np.eye(2)[y_test1_beforejm1]\n",
    "\n",
    "y_train1_beforekc1= y_train1kc1\n",
    "y_train_one_hotkc1 = np.eye(2)[y_train1_beforekc1]\n",
    "\n",
    "y_test1_beforekc1= y_test1kc1\n",
    "y_test_one_hotkc1  = np.eye(2)[y_test1_beforekc1]\n",
    "\n",
    "\n",
    "y_train1_beforekc2= y_train1kc2\n",
    "y_train_one_hotkc2 = np.eye(2)[y_train1_beforekc2]\n",
    "\n",
    "y_test1_beforekc2= y_test1kc2\n",
    "y_test_one_hotkc2  = np.eye(2)[y_test1_beforekc2]\n",
    "\n",
    "y_train1_beforepc1= y_train1pc1\n",
    "y_train_one_hotpc1 = np.eye(2)[y_train1_beforepc1]\n",
    "\n",
    "y_test1_beforepc1= y_test1pc1\n",
    "y_test_one_hotpc1  = np.eye(2)[y_test1_beforepc1]\n",
    "\n",
    "print(y_test_one_hot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the data into Pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('x_train.pkl', 'wb') as f:\n",
    "    pickle.dump(x_train1, f)\n",
    "\n",
    "with open('x_test.pkl', 'wb') as f:\n",
    "    pickle.dump(x_test1, f)\n",
    "\n",
    "with open('y_train.pkl', 'wb') as f:\n",
    "    pickle.dump(y_train_one_hot, f)\n",
    "\n",
    "with open('y_test.pkl', 'wb') as f:\n",
    "    pickle.dump(y_test_one_hot, f)\n",
    "    \n",
    "with open('x_traincm1.pkl', 'wb') as f:\n",
    "    pickle.dump(x_train1cm1, f)\n",
    "\n",
    "with open('x_testcm1.pkl', 'wb') as f:\n",
    "    pickle.dump(x_test1cm1, f)\n",
    "\n",
    "with open('y_traincm1.pkl', 'wb') as f:\n",
    "    pickle.dump(y_train_one_hotcm1, f)\n",
    "\n",
    "with open('y_testcm1.pkl', 'wb') as f:\n",
    "    pickle.dump(y_test_one_hotcm1, f)\n",
    "    \n",
    "with open('x_trainjm1.pkl', 'wb') as f:\n",
    "    pickle.dump(x_train1jm1, f)\n",
    "\n",
    "with open('x_testjm1.pkl', 'wb') as f:\n",
    "    pickle.dump(x_test1jm1, f)\n",
    "\n",
    "with open('y_trainjm1.pkl', 'wb') as f:\n",
    "    pickle.dump(y_train_one_hotjm1, f)\n",
    "\n",
    "with open('y_testjm1.pkl', 'wb') as f:\n",
    "    pickle.dump(y_test_one_hotjm1, f)\n",
    "    \n",
    "with open('x_trainkc1.pkl', 'wb') as f:\n",
    "    pickle.dump(x_train1kc1, f)\n",
    "\n",
    "with open('x_testkc1.pkl', 'wb') as f:\n",
    "    pickle.dump(x_test1kc1, f)\n",
    "\n",
    "with open('y_trainkc1.pkl', 'wb') as f:\n",
    "    pickle.dump(y_train_one_hotkc1, f)\n",
    "\n",
    "with open('y_testkc1.pkl', 'wb') as f:\n",
    "    pickle.dump(y_test_one_hotkc1, f)\n",
    "\n",
    "with open('x_trainkc2.pkl', 'wb') as f:\n",
    "    pickle.dump(x_train1kc2, f)\n",
    "\n",
    "with open('x_testkc2.pkl', 'wb') as f:\n",
    "    pickle.dump(x_test1kc2, f)\n",
    "\n",
    "with open('y_trainkc2.pkl', 'wb') as f:\n",
    "    pickle.dump(y_train_one_hotkc2, f)\n",
    "\n",
    "with open('y_testkc2.pkl', 'wb') as f:\n",
    "    pickle.dump(y_test_one_hotkc2, f)\n",
    "    \n",
    "with open('x_trainpc1.pkl', 'wb') as f:\n",
    "    pickle.dump(x_train1pc1, f)\n",
    "\n",
    "with open('x_testpc1.pkl', 'wb') as f:\n",
    "    pickle.dump(x_test1pc1, f)\n",
    "\n",
    "with open('y_trainpc1.pkl', 'wb') as f:\n",
    "    pickle.dump(y_train_one_hotpc1, f)\n",
    "\n",
    "with open('y_testpc1.pkl', 'wb') as f:\n",
    "    pickle.dump(y_test_one_hotpc1, f)\n",
    "\n",
    "with open('y_train_before1.pkl', 'wb') as f:\n",
    "    pickle.dump(y_train1_before, f)\n",
    "\n",
    "with open('y_test_before1.pkl', 'wb') as f:\n",
    "    pickle.dump(y_test1_before, f)\n",
    "    \n",
    "with open('y_train_before1cm1.pkl', 'wb') as f:\n",
    "    pickle.dump(y_train1_beforecm1, f)\n",
    "\n",
    "with open('y_test_before1cm1.pkl', 'wb') as f:\n",
    "    pickle.dump(y_test1_beforecm1, f)\n",
    "\n",
    "with open('y_train_before1jm1.pkl', 'wb') as f:\n",
    "    pickle.dump(y_train1_beforejm1, f)\n",
    "\n",
    "with open('y_test_before1jm1.pkl', 'wb') as f:\n",
    "    pickle.dump(y_test1_beforejm1, f)\n",
    "    \n",
    "with open('y_train_before1kc1.pkl', 'wb') as f:\n",
    "    pickle.dump(y_train1_beforekc1, f)\n",
    "\n",
    "with open('y_test_before1kc1.pkl', 'wb') as f:\n",
    "    pickle.dump(y_test1_beforekc1, f)\n",
    "    \n",
    "with open('y_train_before1kc2.pkl', 'wb') as f:\n",
    "    pickle.dump(y_train1_beforekc2, f)\n",
    "\n",
    "with open('y_test_before1kc2.pkl', 'wb') as f:\n",
    "    pickle.dump(y_test1_beforekc2, f)\n",
    "    \n",
    "with open('y_train_before1pc1.pkl', 'wb') as f:\n",
    "    pickle.dump(y_train1_beforepc1, f)\n",
    "\n",
    "with open('y_test_before1pc1.pkl', 'wb') as f:\n",
    "    pickle.dump(y_test1_beforepc1, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
